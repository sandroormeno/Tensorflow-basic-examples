{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.8.0\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_fp = tf.keras.utils.get_file(fname= os.path.basename(\"iris_training.csv\") ,\n",
    "                                           origin=\"iris_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local copy of the dataset file: /home/ubuntu/.keras/datasets/iris_training.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Local copy of the dataset file: {}\".format(train_dataset_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120,4,setosa,versicolor,virginica\r\n",
      "6.4,2.8,5.6,2.2,2\r\n",
      "5.0,2.3,3.3,1.0,1\r\n",
      "4.9,2.5,4.5,1.7,2\r\n",
      "4.9,3.1,1.5,0.1,0\r\n"
     ]
    }
   ],
   "source": [
    "!head -n5 {train_dataset_fp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    train_dataset_fp,\n",
    "    batch_size, \n",
    "    column_names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'],\n",
    "    label_name='species',\n",
    "    num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'petal_length': <tf.Tensor: id=294, shape=(32,), dtype=float32, numpy=\n",
       " array([1.5, 5. , 5.8, 5.4, 5.3, 1.5, 5. , 1.4, 5.5, 4.8, 1.6, 1.5, 4.7,\n",
       "        1.7, 1.3, 4.5, 4.7, 1.2, 4.6, 4.9, 1. , 5.6, 6.4, 1.4, 3.3, 1.6,\n",
       "        4.5, 6.3, 5.1, 1.3, 1.6, 3. ], dtype=float32)>,\n",
       " 'petal_width': <tf.Tensor: id=295, shape=(32,), dtype=float32, numpy=\n",
       " array([0.3, 1.7, 1.6, 2.3, 2.3, 0.1, 1.9, 0.3, 1.8, 1.4, 0.6, 0.1, 1.4,\n",
       "        0.3, 0.4, 1.5, 1.6, 0.2, 1.5, 1.8, 0.2, 2.1, 2. , 0.2, 1. , 0.2,\n",
       "        1.3, 1.8, 1.8, 0.2, 0.2, 1.1], dtype=float32)>,\n",
       " 'sepal_length': <tf.Tensor: id=296, shape=(32,), dtype=float32, numpy=\n",
       " array([5.1, 6.7, 7.2, 6.2, 6.4, 4.9, 6.3, 4.8, 6.5, 6.8, 5. , 4.9, 6.1,\n",
       "        5.7, 5.4, 6.2, 6.3, 5.8, 6.5, 6.3, 4.6, 6.4, 7.9, 4.4, 5. , 4.8,\n",
       "        5.7, 7.3, 5.9, 4.4, 4.7, 5.1], dtype=float32)>,\n",
       " 'sepal_width': <tf.Tensor: id=297, shape=(32,), dtype=float32, numpy=\n",
       " array([3.8, 3. , 3. , 3.4, 3.2, 3.1, 2.5, 3. , 3. , 2.8, 3.5, 3.1, 2.9,\n",
       "        3.8, 3.9, 2.2, 3.3, 4. , 2.8, 2.7, 3.6, 2.8, 3.8, 2.9, 2.3, 3.1,\n",
       "        2.8, 2.9, 3. , 3.2, 3.2, 2.5], dtype=float32)>}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.5, 4.4, 5.6, 3.8, 1.5, 1.3, 4.5, 1.9, 5.1, 4.1, 1.2, 3.9, 1.6,\n",
       "       1.3, 4.9, 4.5, 5.3, 5.1, 5.6, 6.1, 3.3, 1.6, 1.4, 1.3, 5.1, 1.5,\n",
       "       5.5, 5.8, 5.2, 5.6, 1.7, 1.4], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['petal_length'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 0, 0, 1, 0, 2, 1, 0, 1, 0, 0, 2, 1, 2, 2, 2, 2, 1, 0,\n",
       "       0, 0, 2, 0, 2, 2, 2, 2, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features, labels = next(iter(train_dataset)) # cada llamada ala función de devuelve un grupo nuevo de valores\n",
    "plt.scatter(features['petal_length'].numpy(),\n",
    "            features['sepal_length'].numpy(),\n",
    "            c=labels.numpy(),\n",
    "            cmap='viridis')\n",
    "\n",
    "plt.xlabel(\"Petal length\")\n",
    "plt.ylabel(\"Sepal length\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etapa de convversión en tensores\n",
    "def pack_features_vector(features, labels):\n",
    "  \"\"\"Pack the features into a single array.\"\"\"\n",
    "  features = tf.stack(list(features.values()), axis=1)\n",
    "  return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(pack_features_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Como tensor: \n",
      " tf.Tensor(\n",
      "[[1.  2.4 4.9 3.3]\n",
      " [2.  3.8 7.9 6.4]\n",
      " [0.2 3.6 4.6 1. ]\n",
      " [1.  2.7 5.8 4.1]\n",
      " [0.2 3.2 4.6 1.4]], shape=(5, 4), dtype=float32)\n",
      "y como arreglo: \n",
      " [[1.  2.4 4.9 3.3]\n",
      " [2.  3.8 7.9 6.4]\n",
      " [0.2 3.6 4.6 1. ]\n",
      " [1.  2.7 5.8 4.1]\n",
      " [0.2 3.2 4.6 1.4]]\n"
     ]
    }
   ],
   "source": [
    "# estas son las caracteristicas en tensores\n",
    "print(\"Como tensor: \\n\",features[:5])\n",
    "print(\"y como arreglo: \\n\", features[:5].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=406, shape=(5,), dtype=int32, numpy=array([1, 2, 0, 1, 0], dtype=int32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estas son las etiquetas en tensores\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# el modelo\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(12, activation=tf.nn.relu, input_shape=(4,)),  # input shape required, num of features  \n",
    "  tf.keras.layers.Dense(12, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(3) # num of labels\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=495, shape=(5, 3), dtype=float32, numpy=\n",
       "array([[ 2.489653  ,  1.1927984 , -0.74202025],\n",
       "       [ 4.0379963 ,  2.159785  , -1.2715418 ],\n",
       "       [ 2.1274235 ,  1.1109865 , -0.55710804],\n",
       "       [ 2.979609  ,  1.4368594 , -0.8849884 ],\n",
       "       [ 2.2098846 ,  1.0265758 , -0.5459739 ]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# una prueba del modelo\n",
    "\n",
    "predictions = model(features)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos devuelve un LOGIT : Vector de predicciones sin procesar (no normalizadas) que genera un modelo de clasificación, que \n",
    "comúnmente se pasa a una función de normalización (activación).\n",
    "Para convertir estos vectores en probabilidades hay que someterlos a una función de activación (softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=513, shape=(5, 3), dtype=float32, numpy=\n",
       "array([[0.7616832 , 0.20823683, 0.03007991],\n",
       "       [0.86370146, 0.13202825, 0.00427032],\n",
       "       [0.6992346 , 0.25304043, 0.04772497],\n",
       "       [0.80987144, 0.1731444 , 0.01698411],\n",
       "       [0.7300239 , 0.22357981, 0.04639626]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7616832 , 0.20823683, 0.03007991]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# este es el resultadp para la pimera fila\n",
    "tf.nn.softmax(predictions[:1]).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente se pude ver que la primera categoría es la que tiene más probabilidades = 0.7616832. Con\n",
    "la función tf.argmax  se verá mucho mejor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    Labels: [1 2 0 1 0 1 1 2 2 1 0 1 2 1 1 2 0 0 1 0 2 0 2 0 0 2 1 0 0 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction: {}\".format(tf.argmax(predictions, axis=1)))\n",
    "print(\"    Labels: {}\".format(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparado con categorias reales, parece que no tenemos buenos resultados.... lo que ocurre es que aú no entrenamos nuestro modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El entrenamiento es la etapa del aprendizaje automático dende el modelo se optimiza gradualmente, o el modelo aprende del dataset (conjunto de datos). El objetivo es aprender lo suficiente de la estructura del data set de entrenamiento para luego hacer predicciones sobre conjunto de nuevos datos. Si nuestro modelo aprende demasiado sobre el dataset de entrenamiento, entonces las predicciones solo funcionan para los datos que ha visto y no serán generalizables. Este problema se llama overfitting (sobreajuste), es muy parecido a memorizar las respuestas en lugar de entender cómo resolver un problema.\n",
    "\n",
    "El problema de clasificación de Iris es un ejemplo de aprendizaje automático supervisado: el modelo se entrena a partir de conjunto de datos que contiene las caraseristicas y las etiquetas. En el aprendizaje automático no supervisado, los ejemplos no contienen etiquetas. En su lugar, el modelo normalmente encuentra patrones entre las características.\n",
    "\n",
    "Definir la función de pérdida y gradiente de desenso.\n",
    "Tanto las etapas de entrenamiento como las de evaluación se deben calcular la tasa de pérdida del modelo. Esto mide la diferencia entre las predicción de un modelo y de la etiqueta deseada, en otras palabras, qué tan mal está trabajando el modelo. Queremos minimizar, u optimizar, este valor.\n",
    "\n",
    "Nuestro modelo calculará su pérdida utilizando la función \"tf.keras.losses.categorical_crossentropy\" que toma las predicciones de probabilidad de clase del modelo y la etiqueta deseada, y devuelve la pérdida promedio en todos los ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss test: 2.0853724479675293\n"
     ]
    }
   ],
   "source": [
    "def loss(model, x, y):\n",
    "  y_ = model(x)\n",
    "  return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
    "\n",
    "\n",
    "l = loss(model, features, labels)\n",
    "print(\"Loss test: {}\".format(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos \"tf.GradientTape\" para calcular los gradientes Y optimizar nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear un optimizador\n",
    "\n",
    "Un optimizador aplica los gradientes calculados a las variables del modelo para minimizar la función de pérdida. Puede pensar en la función de pérdida como una superficie curva (consulte la Figura 3) y queremos encontrar su punto más bajo caminando. Los gradientes apuntan en la dirección del ascenso más empinado, por lo que viajaremos en sentido contrario y seguiremos subiendo la cuesta. Al calcular de forma iterativa la pérdida y el gradiente de cada lote, ajustaremos el modelo durante el entrenamiento. Gradualmente, el modelo encontrará la mejor combinación de pesos y sesgos para minimizar la pérdida. Y cuanto más baja sea la pérdida, mejores serán las predicciones del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Este modelo utiliza el tf.train.GradientDescentOptimizer que implementa el algoritmo de descenso de gradiente estocástico (SGD). La tasa de aprendizaje establece el tamaño de paso que se debe tomar para cada iteración cuesta abajo. Este es un hiperparámetro que comúnmente se ajustará para lograr mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "global_step = tf.contrib.eager.Variable(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Initial Loss: 2.0853724479675293\n",
      "Step: 1,         Loss: 1.5453872680664062\n"
     ]
    }
   ],
   "source": [
    "loss_value, grads = grad(model, features, labels)\n",
    "\n",
    "print(\"Step: {}, Initial Loss: {}\".format(global_step.numpy(),\n",
    "                                          loss_value.numpy()))\n",
    "\n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables), global_step)\n",
    "\n",
    "print(\"Step: {},         Loss: {}\".format(global_step.numpy(),\n",
    "                                          loss(model, features, labels).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ciclos de entrenamiento:\n",
    "\n",
    "¡Con todas las piezas en su lugar, el modelo está listo para el entrenamiento! Un ciclo de entrenamiento alimenta los ejemplos de conjuntos de datos en el modelo para ayudarlo a hacer mejores predicciones. El siguiente bloque de código configura estos pasos de entrenamiento:\n",
    "\n",
    "Iterar cada época. Una época es un paso por el conjunto de datos.\n",
    "Dentro de una época, repita cada ejemplo en el conjunto de datos de entrenamiento, capturando sus características (x) y etiqueta (y).\n",
    "Usando las características del ejemplo, haga una predicción y compárela con la etiqueta. Mida la inexactitud de la predicción y úselo para calcular la pérdida y los gradientes del modelo.\n",
    "Use un optimizador para actualizar las variables del modelo.\n",
    "Mantenga un registro de algunas estadísticas para la visualización.\n",
    "Repita para cada época.\n",
    "La variable num_epochs es el número de veces que se recorre la colección del conjunto de datos. Contraintuitivamente, entrenar un modelo por más tiempo no garantiza un mejor modelo. num_epochs es un hiperparámetro que puede sintonizar. Elegir el número correcto generalmente requiere experiencia y experimentación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 1.311, Accuracy: 50.000%\n",
      "Epoch 050: Loss: 0.330, Accuracy: 93.333%\n",
      "Epoch 100: Loss: 0.225, Accuracy: 96.667%\n",
      "Epoch 150: Loss: 0.150, Accuracy: 96.667%\n",
      "Epoch 200: Loss: 0.143, Accuracy: 97.500%\n"
     ]
    }
   ],
   "source": [
    "## Note: Rerunning this cell uses the same model variables\n",
    "\n",
    "from tensorflow import contrib\n",
    "tfe = contrib.eager\n",
    "\n",
    "# keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 201\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  epoch_loss_avg = tfe.metrics.Mean()\n",
    "  epoch_accuracy = tfe.metrics.Accuracy()\n",
    "\n",
    "  # Training loop - using batches of 32\n",
    "  for x, y in train_dataset:\n",
    "    # Optimize the model\n",
    "    loss_value, grads = grad(model, x, y)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables),\n",
    "                              global_step)\n",
    "\n",
    "    # Track progress\n",
    "    epoch_loss_avg(loss_value)  # add current batch loss\n",
    "    # compare predicted label to actual label\n",
    "    epoch_accuracy(tf.argmax(model(x), axis=1, output_type=tf.int32), y)\n",
    "\n",
    "  # end epoch\n",
    "  train_loss_results.append(epoch_loss_avg.result())\n",
    "  train_accuracy_results.append(epoch_accuracy.result())\n",
    "  \n",
    "  if epoch % 50 == 0:\n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuar : https://www.tensorflow.org/tutorials/eager/custom_training_walkthrough"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
